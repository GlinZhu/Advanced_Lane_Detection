{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advanced Lane Finding Project\n",
    "\n",
    "The goals / steps of this project are the following:\n",
    "\n",
    "* Compute the camera calibration matrix and distortion coefficients given a set of chessboard images.\n",
    "* Apply a distortion correction to raw images.\n",
    "* Use color transforms, gradients, etc., to create a thresholded binary image.\n",
    "* Apply a perspective transform to rectify binary image (\"birds-eye view\").\n",
    "* Detect lane pixels and fit to find the lane boundary.\n",
    "* Determine the curvature of the lane and vehicle position with respect to center.\n",
    "* Warp the detected lane boundaries back onto the original image.\n",
    "* Output visual display of the lane boundaries and numerical estimation of lane curvature and vehicle position.\n",
    "\n",
    "---\n",
    "## First, I'll compute the camera calibration using chessboard images, and extract the object points and images points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute camera calibration and distortion correction for chessboard images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# prepare object points, like (0,0,0), (1,0,0), (2,0,0) ....,(6,5,0)\n",
    "nx=9\n",
    "ny=6\n",
    "objp = np.zeros((nx*ny,3), np.float32)\n",
    "objp[:,:2] = np.mgrid[0:nx,0:ny].T.reshape(-1,2)\n",
    "\n",
    "# Arrays to store object points and image points from all the images.\n",
    "objpoints = [] # 3d points in real world space\n",
    "imgpoints = [] # 2d points in image plane.\n",
    "\n",
    "# Make a list of calibration images\n",
    "images = glob.glob('../camera_cal/calibration*.jpg')\n",
    "\n",
    "# Step through the list and search for chessboard corners\n",
    "for fname in images:\n",
    "    img = cv2.imread(fname)\n",
    "    gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Find the chessboard corners\n",
    "    ret, corners = cv2.findChessboardCorners(gray, (9,6),None)\n",
    "    \n",
    "\n",
    "    # If found, add object points, image points\n",
    "    if ret == True:\n",
    "        objpoints.append(objp)\n",
    "        imgpoints.append(corners)\n",
    "        #ret, mtx, dist, rvecs, tvecs = cv2.calibrateCamera(objpoints, imgpoints, gray.shape[::-1], None, None)\n",
    "\n",
    "        # Draw and display the corners\n",
    "        img = cv2.drawChessboardCorners(img, (9,6), corners, ret)\n",
    "        cv2.imshow('img',img)\n",
    "        cv2.waitKey(500)\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Undistort and unwarp the images using camera calibration and perspective transform for Chessboards "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# prepare object points, like (0,0,0), (1,0,0), (2,0,0) ....,(6,5,0)\n",
    "nx=9\n",
    "ny=6\n",
    "objp = np.zeros((nx*ny,3), np.float32)\n",
    "objp[:,:2] = np.mgrid[0:nx,0:ny].T.reshape(-1,2)\n",
    "\n",
    "# Arrays to store object points and image points from all the images.\n",
    "objpoints = [] # 3d points in real world space\n",
    "imgpoints = [] # 2d points in image plane.\n",
    "\n",
    "# Make a list of calibration images\n",
    "images = glob.glob('../camera_cal/calibration*.jpg')\n",
    "img=cv2.imread(images[19])\n",
    "img=np.array(img)\n",
    "\n",
    "## Define the function for image unwarp\n",
    "def Unwarp_img(img, nx, ny):\n",
    "        # Find the chessboard corners\n",
    "    gray=cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    ret, corners=cv2.findChessboardCorners(gray, (nx, ny), None)\n",
    "    if ret == True:\n",
    "        objpoints.append(objp)\n",
    "        imgpoints.append(corners)\n",
    "        ret, mtx, dist, rvecs, tvecs = cv2.calibrateCamera(objpoints, imgpoints, gray.shape[::-1], None, None)\n",
    "\n",
    "        undist = cv2.undistort(img, mtx, dist, None, mtx)\n",
    "        offset=100 \n",
    "        img_size=(gray.shape[1],gray.shape[0])\n",
    "        src=np.float32([corners[0,:,:], corners[nx-1,:,:],corners[-1,:,:],corners[-nx,:,:]])\n",
    "        dst = np.float32([[offset, offset], [img_size[0]-offset, offset], \n",
    "                                     [img_size[0]-offset, img_size[1]-offset], \n",
    "                                     [offset, img_size[1]-offset]])\n",
    "        # Given src and dst points, calculate the perspective transform matrix\n",
    "        M = cv2.getPerspectiveTransform(src, dst)\n",
    "        Minv = cv2.getPerspectiveTransform(dst, src)\n",
    "        # Warp the image using OpenCV warpPerspective()\n",
    "        warped = cv2.warpPerspective(undist, M, img_size)\n",
    "    return warped, M\n",
    "\n",
    "warped_img, perspective_M=Unwarp_img(img, nx, ny)\n",
    "\n",
    "f, (ax1, ax2) = plt.subplots(1, 2, figsize=(24, 9))\n",
    "f.tight_layout()\n",
    "ax1.imshow(img)\n",
    "ax1.set_title('Original Image', fontsize=30)\n",
    "ax2.imshow(warped_img)\n",
    "ax2.set_title('Undistorted and Warped Image', fontsize=30)\n",
    "plt.savefig('Undistorted_Warped_Image.png')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline for Lane detection on images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define all functions\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply Camera calibration, distortion correction, color&gradients threshold and perspective transforms to the raw testing images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "## Apply Camera calibration, distortion correction\n",
    "def camera_calibration():\n",
    "    nx=9\n",
    "    ny=6\n",
    "    objp = np.zeros((nx*ny,3), np.float32)\n",
    "    objp[:,:2] = np.mgrid[0:nx,0:ny].T.reshape(-1,2)\n",
    "\n",
    "# Arrays to store object points and image points from all the images.\n",
    "    objpoints = [] # 3d points in real world space\n",
    "    imgpoints = [] # 2d points in image plane.\n",
    "\n",
    "# Make a list of calibration images\n",
    "    images = glob.glob('../camera_cal/calibration*.jpg')\n",
    "\n",
    "# Step through the list and search for chessboard corners\n",
    "    for fname in images:\n",
    "        img_chess = cv2.imread(fname)\n",
    "        gray_chess = cv2.cvtColor(img_chess,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Find the chessboard corners\n",
    "        ret, corners = cv2.findChessboardCorners(gray_chess, (9,6),None)\n",
    "    \n",
    "\n",
    "    # If found, add object points, image points\n",
    "        if ret == True:\n",
    "            objpoints.append(objp)\n",
    "            imgpoints.append(corners)\n",
    "    shape=gray_chess.shape[::-1]\n",
    "    np.save('objpoints', objpoints)\n",
    "    np.save('imgpoints', imgpoints)\n",
    "    np.save('shape', shape)\n",
    "    \n",
    "    return None\n",
    "## Apply Camera calibration, distortion correction\n",
    "def undistortion(img):\n",
    "# Arrays to store object points and image points from all the images.\n",
    "    objpoints = np.load('objpoints.npy') # 3d points in real world space\n",
    "    imgpoints = np.load('imgpoints.npy') # 2d points in image plane.\n",
    "    shape=tuple(np.load('shape.npy'))\n",
    "    ret, mtx, dist, rvecs, tvecs = cv2.calibrateCamera(objpoints, imgpoints,shape,None, None)\n",
    "    undist=cv2.undistort(img, mtx, dist, None, mtx)\n",
    "    return undist  \n",
    "\n",
    "# read an image from a folder\n",
    "#img=mpimg.imread('solidYellowCurve2.jpg')\n",
    "img=cv2.imread('../test_images/test6.jpg')\n",
    "b,g,r=cv2.split(img)\n",
    "img=cv2.merge([r,g,b])\n",
    "# print out some info about this image\n",
    "#img=cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "print ('This image is:', type(img),'with dimensions of',img.shape)\n",
    "\n",
    "# transform from color to gray scale\n",
    "img_gray=cv2.cvtColor(img,cv2.COLOR_RGB2GRAY) #mpimg loads image as RGB\n",
    "dst=undistortion(img)\n",
    "f, (ax1, ax2)=plt.subplots(1,2, figsize=(24,9))\n",
    "f.tight_layout()\n",
    "ax1.imshow(img)\n",
    "ax1.set_title('Original Image', fontsize=30)\n",
    "ax2.imshow(dst)\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresh_grad_min = 20\n",
    "thresh_grad_max = 100\n",
    "color_thre_min, color_thre_max=170, 255\n",
    "## Define Color & gradients function\n",
    "def gradient_threshold(img, thresh_grad_min, thresh_grad_max, color_thre_min, color_thre_max):\n",
    "    hls=cv2.cvtColor(img, cv2.COLOR_RGB2HLS)\n",
    "    s_channel=hls[:,:,2]\n",
    "    gray=cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    \n",
    "    ## Sobelx\n",
    "    sobelx = cv2.Sobel(gray, cv2.CV_64F, 1, 0) # Take the derivative in x\n",
    "    abs_sobelx = np.absolute(sobelx) # Absolute x derivative to accentuate lines away from horizontal\n",
    "    scaled_sobel = np.uint8(255*abs_sobelx/np.max(abs_sobelx))\n",
    "    # Threshold x gradient\n",
    "    sxbinary = np.zeros_like(scaled_sobel)\n",
    "    sxbinary[(scaled_sobel >= thresh_grad_min) & (scaled_sobel <= thresh_grad_max)] = 1\n",
    "    \n",
    "    # Color threshold\n",
    "    s_binary=np.zeros_like(s_channel)\n",
    "    s_binary[(s_channel>=color_thre_min)&(s_channel<color_thre_max)]=1\n",
    "    # stack each channel to an image to see the contribution of individual channels\n",
    "    color_binary = np.dstack(( np.zeros_like(sxbinary), sxbinary, s_binary)) * 255\n",
    "    # combine two binary thresholds\n",
    "    combined_binary=np.zeros_like(s_binary)\n",
    "    combined_binary[(sxbinary==1)|(s_binary==1)]=1\n",
    "    return  combined_binary\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## Perspective transform\n",
    "\n",
    "## Define the function for image unwarp\n",
    "def warped_img(img):\n",
    "    gray=cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    img_size=(gray.shape[1],gray.shape[0])\n",
    "    #src=np.float32([[500,500],[780,500],[img.shape[1],img.shape[0]],[150,img.shape[0]]])\n",
    "    src=np.float32([[580,460],[700,460],[1040,680],[260,680]])\n",
    "    dst = np.array([[200, 0], [1000, 0], [1000, img.shape[0]], [200, img.shape[0]]], np.float32)\n",
    "# Given src and dst points, calculate the perspective transform matrix\n",
    "    M = cv2.getPerspectiveTransform(src, dst)\n",
    "    Minv = cv2.getPerspectiveTransform(dst, src)\n",
    "# Warp the image using OpenCV warpPerspective()\n",
    "    warped = cv2.warpPerspective(img, M, img_size,flags=cv2.INTER_LINEAR)\n",
    "    return warped\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define the function of detecting lane lines\n",
    "\n",
    "def find_lines(binary):\n",
    "    # calculate the current base leftx and rightx pixels location\n",
    "    image_height=binary.shape[0]\n",
    "    image_width=binary.shape[1]\n",
    "    histogram=np.sum(binary[binary.shape[0]//2:,:], axis=0)\n",
    "    midpoint=np.int(binary.shape[1]//2)\n",
    "    leftx_base=np.argmax(histogram[:midpoint])           # define the base left lanes location\n",
    "    rightx_base=np.argmax(histogram[midpoint:])+midpoint  # define the base right lanes location\n",
    "    leftx_current=leftx_base\n",
    "    rightx_current=rightx_base\n",
    "    out_img=np.dstack((binary, binary, binary))\n",
    "    # nonzero x & y locations\n",
    "    nonzerox=np.array(binary.nonzero()[1])\n",
    "    nonzeroy=np.array(binary.nonzero()[0])\n",
    "    # left and right lane lines indices\n",
    "    leftx_ind, rightx_ind=[],[]\n",
    "    # Hyper parameters for windows\n",
    "    nwindow=9\n",
    "    margin=100\n",
    "    minpxl=50\n",
    "    \n",
    "    for window in range(nwindow):\n",
    "        # define the parameters of windwos on image\n",
    "        win_height=np.int(image_height//nwindow)\n",
    "        win_y_low=image_height-(window+1)*win_height\n",
    "        win_y_high=image_height-window*win_height\n",
    "        win_left_low=leftx_current-margin\n",
    "        win_left_high=leftx_current+margin\n",
    "        win_right_low=rightx_current-margin\n",
    "        win_right_high=rightx_current+margin\n",
    "        \n",
    "        # identify the nonzero pixels within the window\n",
    "        detected_leftx_ind=((nonzeroy >= win_y_low) & (nonzeroy < win_y_high) & \n",
    "        (nonzerox >= win_left_low) &  (nonzerox < win_left_high)).nonzero()[0]\n",
    "        \n",
    "        detected_rightx_ind=((nonzeroy >= win_y_low) & (nonzeroy < win_y_high) & \n",
    "        (nonzerox >= win_right_low) &  (nonzerox < win_right_high)).nonzero()[0]\n",
    "        \n",
    "        if len(detected_leftx_ind)>minpxl:\n",
    "            leftx_current=np.int(np.mean(nonzerox[detected_leftx_ind]))\n",
    "        if len(detected_rightx_ind)>minpxl:\n",
    "            rightx_current=np.int(np.mean(nonzerox[detected_rightx_ind]))\n",
    "        leftx_ind.append(detected_leftx_ind)\n",
    "        rightx_ind.append(detected_rightx_ind)\n",
    "    try:\n",
    "        leftx_ind=np.concatenate(leftx_ind)\n",
    "        rightx_ind=np.concatenate(rightx_ind)\n",
    "    except ValueErrors:\n",
    "        \n",
    "        pass\n",
    "    \n",
    "    leftx=nonzerox[leftx_ind]\n",
    "    rightx=nonzerox[rightx_ind]\n",
    "    lefty=nonzeroy[leftx_ind]\n",
    "    righty=nonzeroy[rightx_ind]\n",
    "    \n",
    "    return leftx, lefty, rightx, righty, out_img\n",
    "\n",
    "# define polynomial function of lane lines\n",
    "\n",
    "def polynomial_fit(binary):\n",
    "    # Find our lane pixels first\n",
    "    leftx, lefty, rightx, righty, out_img = find_lines(binary)\n",
    "\n",
    "    # Fit a second order polynomial to each using `np.polyfit`\n",
    "    left_fit = np.polyfit(lefty, leftx, 2)\n",
    "    right_fit = np.polyfit(righty, rightx, 2)\n",
    "    # Generate x and y values for plotting\n",
    "    ploty = np.linspace(0, binary.shape[0]-1, binary.shape[0] )\n",
    "    try:\n",
    "        left_fitx = left_fit[0]*ploty**2 + left_fit[1]*ploty + left_fit[2]\n",
    "        right_fitx = right_fit[0]*ploty**2 + right_fit[1]*ploty + right_fit[2]\n",
    "    except TypeError:\n",
    "        # Avoids an error if `left` and `right_fit` are still none or incorrect\n",
    "        print('The function failed to fit a line!')\n",
    "        left_fitx = 1*ploty**2 + 1*ploty\n",
    "        right_fitx = 1*ploty**2 + 1*ploty\n",
    "\n",
    "    ## Visualization ##\n",
    "    # Colors in the left and right lane regions\n",
    "    out_img[lefty, leftx] = [255, 0, 0]\n",
    "    out_img[righty, rightx] = [0, 0, 255]\n",
    "\n",
    "    # Plots the left and right polynomials on the lane lines\n",
    "    plt.plot(left_fitx, ploty, color='yellow')\n",
    "    plt.plot(right_fitx, ploty, color='yellow')\n",
    "    \n",
    "    return out_img\n",
    "    \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def curvature_cal(binary):\n",
    "    # Find our lane pixels first\n",
    "    leftx, lefty, rightx, righty, out_img = find_lines(binary)\n",
    "    # covert x, y from pixels to meters\n",
    "    ym_per_pix = 30/720 # meters per pixel in y dimension\n",
    "    xm_per_pix = 3.7/700 # meters per pixel in x dimension\n",
    "\n",
    "    # Fit a second order polynomial to each using `np.polyfit`\n",
    "    left_fit_cr = np.polyfit(lefty*ym_per_pix, leftx*xm_per_pix, 2)\n",
    "    right_fit_cr = np.polyfit(righty*ym_per_pix, rightx*xm_per_pix, 2)\n",
    "\n",
    "    # Generate x and y values for plotting\n",
    "    ploty = np.linspace(0, binary.shape[0]-1, binary.shape[0] )\n",
    "    y_eval=np.max(ploty)\n",
    "    left_curverad = ((1 + (2*left_fit_cr[0]*y_eval*ym_per_pix + left_fit_cr[1])**2)**1.5) / np.absolute(2*left_fit_cr[0])\n",
    "    right_curverad = ((1 + (2*right_fit_cr[0]*y_eval*ym_per_pix + right_fit_cr[1])**2)**1.5) / np.absolute(2*right_fit_cr[0])\n",
    "    \n",
    "\n",
    "    return left_curverad, right_curverad\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline (Video)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing some useful packages\n",
    "#from moviepy.editor import VideoFileClip\n",
    "import imageio\n",
    "imageio.plugins.ffmpeg.download()\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import matplotlib.image as mpimg\n",
    "import cv2\n",
    "import os\n",
    "from moviepy.editor import VideoFileClip\n",
    "import glob\n",
    "\n",
    "## Apply Camera calibration, distortion correction\n",
    "def undistortion(img):\n",
    "# Arrays to store object points and image points from all the images.\n",
    "    objpoints = np.load('objpoints.npy') # 3d points in real world space\n",
    "    imgpoints = np.load('imgpoints.npy') # 2d points in image plane.\n",
    "    shape=tuple(np.load('shape.npy'))\n",
    "    ret, mtx, dist, rvecs, tvecs = cv2.calibrateCamera(objpoints, imgpoints,shape,None, None)\n",
    "    undist=cv2.undistort(img, mtx, dist, None, mtx)\n",
    "    return undist\n",
    "\n",
    "thresh_grad_min = 20\n",
    "thresh_grad_max = 100\n",
    "color_thre_min, color_thre_max=170, 255\n",
    "## Define Color & gradients function\n",
    "def gradient_threshold(img, thresh_grad_min, thresh_grad_max, color_thre_min, color_thre_max):\n",
    "    hls=cv2.cvtColor(img, cv2.COLOR_RGB2HLS)\n",
    "    s_channel=hls[:,:,2]\n",
    "    gray=cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    \n",
    "    ## Sobelx\n",
    "    sobelx = cv2.Sobel(gray, cv2.CV_64F, 1, 0) # Take the derivative in x\n",
    "    abs_sobelx = np.absolute(sobelx) # Absolute x derivative to accentuate lines away from horizontal\n",
    "    scaled_sobel = np.uint8(255*abs_sobelx/np.max(abs_sobelx))\n",
    "    # Threshold x gradient\n",
    "    sxbinary = np.zeros_like(scaled_sobel)\n",
    "    sxbinary[(scaled_sobel >= thresh_grad_min) & (scaled_sobel <= thresh_grad_max)] = 1\n",
    "    \n",
    "    # Color threshold\n",
    "    s_binary=np.zeros_like(s_channel)\n",
    "    s_binary[(s_channel>=color_thre_min)&(s_channel<color_thre_max)]=1\n",
    "    # stack each channel to an image to see the contribution of individual channels\n",
    "    color_binary = np.dstack(( np.zeros_like(sxbinary), sxbinary, s_binary)) * 255\n",
    "    # combine two binary thresholds\n",
    "    combined_binary=np.zeros_like(s_binary)\n",
    "    combined_binary[(sxbinary==1)|(s_binary==1)]=1\n",
    "    return  combined_binary\n",
    "\n",
    "## Perspective transform\n",
    "## Define the function for image unwarp\n",
    "def warped_img(img):\n",
    "    gray=cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    img_size=(gray.shape[1],gray.shape[0])\n",
    "    #src=np.float32([[500,500],[780,500],[img.shape[1],img.shape[0]],[150,img.shape[0]]])\n",
    "    src=np.float32([[580,460],[700,460],[1040,680],[260,680]])\n",
    "    dst = np.array([[200, 0], [1000, 0], [1000, img.shape[0]], [200, img.shape[0]]], np.float32)\n",
    "# Given src and dst points, calculate the perspective transform matrix\n",
    "    M = cv2.getPerspectiveTransform(src, dst)\n",
    "    Minv = cv2.getPerspectiveTransform(dst, src)\n",
    "# Warp the image using OpenCV warpPerspective()\n",
    "    warped = cv2.warpPerspective(img, M, img_size)\n",
    "    return warped, M, Minv\n",
    "\n",
    "## Define the function of detecting lane lines\n",
    "\n",
    "def find_lines(binary):\n",
    "    # calculate the current base leftx and rightx pixels location\n",
    "    image_height=binary.shape[0]\n",
    "    image_width=binary.shape[1]\n",
    "    histogram=np.sum(binary[binary.shape[0]//2:,:], axis=0)\n",
    "    midpoint=np.int(binary.shape[1]//2)\n",
    "    leftx_base=np.argmax(histogram[:midpoint])           # define the base left lanes location\n",
    "    rightx_base=np.argmax(histogram[midpoint:])+midpoint  # define the base right lanes location\n",
    "    leftx_current=leftx_base\n",
    "    rightx_current=rightx_base\n",
    "    out_img=np.dstack((binary, binary, binary))\n",
    "    # nonzero x & y locations\n",
    "    nonzerox=np.array(binary.nonzero()[1])\n",
    "    nonzeroy=np.array(binary.nonzero()[0])\n",
    "    # left and right lane lines indices\n",
    "    leftx_ind, rightx_ind=[],[]\n",
    "    # Hyper parameters for windows\n",
    "    nwindow=9\n",
    "    margin=100\n",
    "    minpxl=50\n",
    "    \n",
    "    for window in range(nwindow):\n",
    "        # define the parameters of windwos on image\n",
    "        win_height=np.int(image_height//nwindow)\n",
    "        win_y_low=image_height-(window+1)*win_height\n",
    "        win_y_high=image_height-window*win_height\n",
    "        win_left_low=leftx_current-margin\n",
    "        win_left_high=leftx_current+margin\n",
    "        win_right_low=rightx_current-margin\n",
    "        win_right_high=rightx_current+margin\n",
    "        \n",
    "        # identify the nonzero pixels within the window\n",
    "        detected_leftx_ind=((nonzeroy >= win_y_low) & (nonzeroy < win_y_high) & \n",
    "        (nonzerox >= win_left_low) &  (nonzerox < win_left_high)).nonzero()[0]\n",
    "        \n",
    "        detected_rightx_ind=((nonzeroy >= win_y_low) & (nonzeroy < win_y_high) & \n",
    "        (nonzerox >= win_right_low) &  (nonzerox < win_right_high)).nonzero()[0]\n",
    "        \n",
    "        if len(detected_leftx_ind)>minpxl:\n",
    "            leftx_current=np.int(np.mean(nonzerox[detected_leftx_ind]))\n",
    "        if len(detected_rightx_ind)>minpxl:\n",
    "            rightx_current=np.int(np.mean(nonzerox[detected_rightx_ind]))\n",
    "        leftx_ind.append(detected_leftx_ind)\n",
    "        rightx_ind.append(detected_rightx_ind)\n",
    "    try:\n",
    "        leftx_ind=np.concatenate(leftx_ind)\n",
    "        rightx_ind=np.concatenate(rightx_ind)\n",
    "    except ValueErrors:\n",
    "        \n",
    "        pass\n",
    "    \n",
    "    leftx=nonzerox[leftx_ind]\n",
    "    rightx=nonzerox[rightx_ind]\n",
    "    lefty=nonzeroy[leftx_ind]\n",
    "    righty=nonzeroy[rightx_ind]\n",
    "    \n",
    "    return leftx, lefty, rightx, righty, out_img\n",
    "\n",
    "# define polynomial function of lane lines\n",
    "\n",
    "def polynomial_fit(binary, Minv):\n",
    "    # Find our lane pixels first\n",
    "    leftx, lefty, rightx, righty, out_img = find_lines(binary)\n",
    "    # Fit a second order polynomial to each using `np.polyfit`\n",
    "    left_fit = np.polyfit(lefty, leftx, 2)\n",
    "    right_fit = np.polyfit(righty, rightx, 2)\n",
    "    # Generate x and y values for plotting\n",
    "    ploty = np.linspace(0, binary.shape[0]-1, binary.shape[0] )\n",
    "    try:\n",
    "        left_fitx = left_fit[0]*ploty**2 + left_fit[1]*ploty + left_fit[2]\n",
    "        right_fitx = right_fit[0]*ploty**2 + right_fit[1]*ploty + right_fit[2]\n",
    "    except TypeError:\n",
    "        # Avoids an error if `left` and `right_fit` are still none or incorrect\n",
    "        print('The function failed to fit a line!')\n",
    "        left_fitx = 1*ploty**2 + 1*ploty\n",
    "        right_fitx = 1*ploty**2 + 1*ploty\n",
    "    \n",
    "    # Create an image to draw the lines on\n",
    "    warp_zero = np.zeros_like(binary).astype(np.uint8)\n",
    "    color_warp = np.dstack((warp_zero, warp_zero, warp_zero))\n",
    "\n",
    "    # Recast the x and y points into usable format for cv2.fillPoly()\n",
    "    pts_left = np.array([np.transpose(np.vstack([left_fitx, ploty]))])\n",
    "    pts_right = np.array([np.flipud(np.transpose(np.vstack([right_fitx, ploty])))])\n",
    "    pts = np.hstack((pts_left, pts_right))\n",
    "\n",
    "    # Draw the lane onto the warped blank image\n",
    "    cv2.fillPoly(color_warp, np.int_([pts]), (0,255, 0))\n",
    "    # Warp the blank back to original image space using inverse perspective matrix (Minv)\n",
    "    newwarp = cv2.warpPerspective(color_warp, Minv, (binary.shape[1], binary.shape[0])) \n",
    "    \n",
    "\n",
    "    ## Visualization ##\n",
    "    # Colors in the left and right lane regions\n",
    "    out_img[lefty, leftx] = [255, 0, 0]\n",
    "    out_img[righty, rightx] = [0, 0, 255]\n",
    "\n",
    "    # Plots the left and right polynomials on the lane lines\n",
    "    #plt.plot(left_fitx, ploty, color='yellow')\n",
    "    #plt.plot(right_fitx, ploty, color='yellow')\n",
    "    return out_img, newwarp\n",
    "\n",
    "def curvature_cal(binary):\n",
    "    # Find our lane pixels first\n",
    "    leftx, lefty, rightx, righty, out_img = find_lines(binary)\n",
    "    # covert x, y from pixels to meters\n",
    "    ym_per_pix = 30/720 # meters per pixel in y dimension\n",
    "    xm_per_pix = 3.7/700 # meters per pixel in x dimension\n",
    "    \n",
    "    image_height=binary.shape[0]\n",
    "    image_width=binary.shape[1]\n",
    "    histogram=np.sum(binary[binary.shape[0]//2:,:], axis=0)\n",
    "    midpoint=np.int(binary.shape[1]//2)\n",
    "    leftx_base=np.argmax(histogram[:midpoint])           # define the base left lanes location\n",
    "    rightx_base=np.argmax(histogram[midpoint:])+midpoint  # define the base right lanes location\n",
    "    lane_center=np.int((leftx_base+rightx_base)//2)\n",
    "    img_center=np.int(image_width//2)\n",
    "    Veh_pos=np.float32((img_center-lane_center)*xm_per_pix)  # calculate the vehicel position, left '-', right off center '+'\n",
    "    \n",
    "    # Fit a second order polynomial to each using `np.polyfit`\n",
    "    left_fit_cr = np.polyfit(lefty*ym_per_pix, leftx*xm_per_pix, 2)\n",
    "    right_fit_cr = np.polyfit(righty*ym_per_pix, rightx*xm_per_pix, 2)\n",
    "\n",
    "    # Generate x and y values for plotting\n",
    "    ploty = np.linspace(0, binary.shape[0]-1, binary.shape[0] )\n",
    "    y_eval=np.max(ploty)\n",
    "    left_curverad = ((1 + (2*left_fit_cr[0]*y_eval*ym_per_pix + left_fit_cr[1])**2)**1.5) / np.absolute(2*left_fit_cr[0])\n",
    "    right_curverad = ((1 + (2*right_fit_cr[0]*y_eval*ym_per_pix + right_fit_cr[1])**2)**1.5) / np.absolute(2*right_fit_cr[0])\n",
    "    lane_curverad=(left_curverad+right_curverad)/2\n",
    "\n",
    "    return lane_curverad, Veh_pos\n",
    "\n",
    "def process_image(img):\n",
    "    # print out some info about this image\n",
    "    #img=cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    # transform from color to gray scale\n",
    "    #b,g,r=cv2.split(img)\n",
    "    #img=cv2.merge([r,g,b])\n",
    "    img_gray=cv2.cvtColor(img,cv2.COLOR_RGB2GRAY) #mpimg loads image as RGB\n",
    "    # Apply Gaussian smoothing \n",
    "    #kernel_size=5\n",
    "    #blur_gray=cv2.GaussianBlur(img_gray,(kernel_size,kernel_size),0,0)\n",
    "    # Undistort the image\n",
    "\n",
    "    undistort_img=undistortion(img)\n",
    "    #color & gradients threshold\n",
    "    img_warped, perspective_M, Minv=warped_img(undistort_img)\n",
    "    warped_binary=gradient_threshold(img_warped, thresh_grad_min, thresh_grad_max, color_thre_min, color_thre_max)\n",
    "\n",
    "    out_img, newwarp=polynomial_fit(warped_binary,Minv)\n",
    "    lane_curverad, Veh_pos=curvature_cal(warped_binary)\n",
    "    # Combine the result with the original image\n",
    "    result = cv2.addWeighted(undistort_img, 1, newwarp, 0.3, 0)\n",
    "    if Veh_pos > 0:\n",
    "        car_pos_text = \"{:04.2f}m right off center\".format(Veh_pos)\n",
    "    else:\n",
    "        car_pos_text = '{:04.3f}m left off center'.format(abs(Veh_pos))\n",
    "\n",
    "    cv2.putText(result, \"Lane curve: {:04.2f}m\".format(lane_curverad), (10, 50), cv2.FONT_HERSHEY_SIMPLEX, 1.5,\n",
    "                color=(255, 255, 255), thickness=2)\n",
    "    cv2.putText(result, \"Car is {}\".format(car_pos_text), (10, 100), cv2.FONT_HERSHEY_SIMPLEX, 1.5, color=(255, 255, 255),\n",
    "                thickness=2)\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] >>>> Building video final_result.mp4\n",
      "[MoviePy] Writing video final_result.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████▉| 1260/1261 [14:06<00:00,  1.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] Done.\n",
      "[MoviePy] >>>> Video ready: final_result.mp4 \n",
      "\n",
      "Wall time: 14min 7s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<video width=\"960\" height=\"540\" controls>\n",
       "  <source src=\"final_result.mp4\">\n",
       "</video>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import HTML\n",
    "white_output = 'final_result.mp4'\n",
    "## To speed up the testing process you may want to try your pipeline on a shorter subclip of the video\n",
    "## To do so add .subclip(start_second,end_second) to the end of the line below\n",
    "## Where start_second and end_second are integer values representing the start and end of the subclip\n",
    "## You may also uncomment the following line for a subclip of the first 5 seconds\n",
    "##clip1 = VideoFileClip(\"test_videos/solidWhiteRight.mp4\").subclip(0,5)\n",
    "clip1 = VideoFileClip(\"../project_video.mp4\")\n",
    "white_clip = clip1.fl_image(process_image) #NOTE: this function expects color images!!\n",
    "%time white_clip.write_videofile(white_output, audio=False)  \n",
    "\n",
    "HTML(\"\"\"\n",
    "<video width=\"960\" height=\"540\" controls>\n",
    "  <source src=\"{0}\">\n",
    "</video>\n",
    "\"\"\".format(white_output))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
